import os
import soundfile as sf
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
from scipy.signal import resample

df = pd.read_csv(r"E:\dataTrain\NewHUmanAndUnhuman\dataset.csv")

# æ ‡ç­¾æ˜ å°„
label_map = {'Huaman': 1, 'unHuaman': 0}
df['label'] = df['Category'].map(label_map)

print(f"ğŸ“Š åŸå§‹ wav æ–‡ä»¶æ•°: {len(df)}")

sample_rate = 16000

slice_ms = 50        # æ¯ä¸ªæ ·æœ¬ = 50msï¼ˆæ¨¡å‹è¾“å…¥ï¼‰
n_fft_ms = 25        # STFT çª—å£ = 25ms
hop_ms = 25          # STFT æ­¥é•¿ = 25ms
n_mels = 50          # Mel é¢‘ç‡ç»´åº¦

n_fft = int(sample_rate * n_fft_ms / 1000)       # 400
hop_length = int(sample_rate * hop_ms / 1000)    # 400
slice_samples = int(sample_rate * slice_ms / 1000)  # 800

output_dir = r"E:\dataTrain\NewHUmanAndUnhuman\npyData50ms2weight"
os.makedirs(output_dir, exist_ok=True)

# =============================
# åˆ‡ç‰‡ + Mel â†’ npy
# =============================

def slice_wav_to_npy(wav_path, label):
    records = []

    try:
        waveform, sr = sf.read(wav_path)  # waveform: [num_samples] æˆ– [num_samples, channels]

        # è½¬ torch.Tensor
        waveform = torch.tensor(waveform, dtype=torch.float32)

        # å•å£°é“
        if waveform.ndim > 1 and waveform.shape[1] > 1:
            waveform = waveform.mean(dim=1, keepdim=True)
        elif waveform.ndim == 1:
            waveform = waveform.unsqueeze(1)  # shape -> [num_samples, 1]

        waveform = waveform.T  # è½¬ä¸º [1, L]ï¼Œä¿æŒå’Œ torchaudio ä¸€è‡´

        # é‡é‡‡æ ·
        if sr != sample_rate:
            L = waveform.shape[1]
            new_len = int(L * sample_rate / sr)
            waveform = torch.tensor(resample(waveform.numpy(), new_len, axis=1), dtype=torch.float32)

        L = waveform.shape[1]

        mel_transform = torch.nn.Sequential(
            torch.nn.Conv1d(1, 1, 1)  # å ä½ï¼Œç”¨äºå…¼å®¹ç»“æ„ï¼Œå¯å¿½ç•¥
        )
        # âš ï¸ è¿™é‡Œä½¿ç”¨ torchaudio.transforms.MelSpectrogram
        # ä»å¯ä½¿ç”¨ torchaudio è¿›è¡Œ Mel å˜æ¢ï¼š
        import torchaudio
        mel_transform = torchaudio.transforms.MelSpectrogram(
            sample_rate=sample_rate,
            n_fft=n_fft,
            hop_length=hop_length,
            n_mels=n_mels,
            center=False
        )

        fname = os.path.splitext(os.path.basename(wav_path))[0]
        slice_count = 0

        for start in range(0, L - slice_samples + 1, slice_samples):
            segment = waveform[:, start:start + slice_samples]
            mel = mel_transform(segment)
            mel_db = 10 * torch.log10(mel + 1e-9)

            out_path = os.path.join(
                output_dir,
                f"{fname}_slice[{start}].npy"
            )

            np.save(out_path, mel_db.numpy())

            records.append({
                "path": out_path,
                "label": label
            })

            slice_count += 1

        print(f"[OK] {fname} â†’ {slice_count} slices")
        return records

    except Exception as e:
        print(f"[ERROR] {wav_path}")
        print(e)
        return []

# =============================
# éå†æ‰€æœ‰ wav
# =============================

all_records = []

for _, row in tqdm(df.iterrows(), total=len(df), desc="å¤„ç†éŸ³é¢‘"):
    all_records.extend(
        slice_wav_to_npy(row['path'], row['label'])
    )

print(f"\nâœ… æ€»åˆ‡ç‰‡æ•°: {len(all_records)}")

# =============================
# ç”Ÿæˆ CSV
# =============================

index_df = pd.DataFrame(all_records)
index_csv = os.path.join(output_dir, "50ms2WeightMel.csv")
index_df.to_csv(index_csv, index=False)

print(f"ğŸ“„ CSV å·²ç”Ÿæˆ: {index_csv}")
